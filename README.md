# Westgate Backend API

An AI-driven city data analysis and intelligence platform that processes urban data from multiple sources to generate actionable insights and reports.

## Overview

Westgate Backend is a FastAPI-based service that aggregates and analyzes city data from various sources including SF311 requests, Reddit discussions, crime statistics, and neighborhood indicators. It uses intelligent agents and LLM services to process data and generate comprehensive reports for urban planning and civic engagement.

## Architecture

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ routes/           # API endpoints
â”‚   â”‚   â”œâ”€â”€ agents.py     # Agent orchestration & triggers
â”‚   â”‚   â”œâ”€â”€ data.py       # Data ingestion & management
â”‚   â”‚   â”œâ”€â”€ reports.py    # Report generation
â”‚   â”‚   â”œâ”€â”€ goals.py      # Goal tracking & management
â”‚   â”‚   â””â”€â”€ knowledge_graph.py  # Knowledge graph operations
â”‚   â”œâ”€â”€ services/         # Core business logic
â”‚   â”‚   â”œâ”€â”€ agents/       # Specialized AI agents
â”‚   â”‚   â”‚   â”œâ”€â”€ sf311_agent.py      # SF311 data analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ reddit_agent.py     # Social media insights
â”‚   â”‚   â”‚   â””â”€â”€ knowledge_graph_agent.py  # Graph operations
â”‚   â”‚   â”œâ”€â”€ agent_framework.py     # Agent orchestration
â”‚   â”‚   â”œâ”€â”€ llm_service.py         # LLM integration
â”‚   â”‚   â”œâ”€â”€ report_generator.py    # Report creation
â”‚   â”‚   â””â”€â”€ data_ingestion.py      # Data processing
â”‚   â”œâ”€â”€ models.py         # Database models
â”‚   â””â”€â”€ database.py      # Database configuration
â”œâ”€â”€ parsers/              # Data source parsers
â”‚   â”œâ”€â”€ 311parser/        # SF311 API integration
â”‚   â””â”€â”€ redditParser/     # Reddit data extraction
â””â”€â”€ requirements.txt      # Python dependencies
```

## Key Features

### ðŸ¤– Intelligent Agents
- **SF311 Agent**: Analyzes city service requests for patterns and insights
- **Reddit Agent**: Extracts community sentiment and local issues
- **Knowledge Graph Agent**: Builds relationships between data points

### ðŸ“Š Intelligent Data Processing
- **Multi-source Ingestion**: Seamlessly processes CSV files, APIs, social media feeds, and real-time data streams
- **Smart Aggregation**: AI-powered data normalization across different formats, schemas, and geographic levels
- **Universal Architecture**: Designed to handle any city, county, or state data with automatic schema detection and mapping
- **Geographic Intelligence**: Advanced spatial analysis with neighborhood, district, and regional mapping
- **Data Harmonization**: Intelligent merging of disparate data sources into unified, queryable datasets

### ðŸ“ˆ Report Generation
- Automated city reports with AI-generated insights
- PDF export functionality
- Customizable report templates

### ðŸŽ¯ Goal Management
- Track civic goals and initiatives
- Progress monitoring and analytics
- Integration with report generation

## Tech Stack

- **Framework**: FastAPI with async/await
- **Database**: SQLite with SQLAlchemy ORM
- **AI/ML**: OpenAI GPT, Anthropic Claude, Sentence Transformers
- **Data Processing**: Pandas, NumPy, FAISS for vector search
- **APIs**: SF311, Reddit, custom data sources

## Quick Start

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Set up environment variables**:
   ```bash
   cp .env.example .env
   # Add your API keys (OpenAI, Anthropic, etc.)
   ```

3. **Run the server**:
   ```bash
   uvicorn app.main:app --reload
   ```

4. **Access the API**:
   - API Documentation: http://localhost:8000/docs
   - Health Check: http://localhost:8000/health

## API Endpoints

- `/api/agents/*` - Agent operations and data triggers
- `/api/reports/*` - Report generation and management
- `/api/data/*` - Data ingestion and querying
- `/api/goals/*` - Goal tracking and analytics
- `/api/knowledge-graph/*` - Knowledge graph operations

## Data Sources & Architecture

### Supported Data Types
- **SF311**: San Francisco service requests and complaints
- **Reddit**: Community discussions and local issues  
- **Crime Data**: Historical crime statistics and trends
- **Neighborhood Indicators**: Demographics and quality metrics
- **Permit Data**: Building and development permits
- **Custom Datasets**: Any CSV or API data from cities, counties, or states

### Intelligent Data Pipeline
The platform features a sophisticated data ingestion architecture that:
- **Auto-detects** data schemas and formats across different sources
- **Normalizes** geographic references (addresses, coordinates, neighborhoods)
- **Harmonizes** temporal data (dates, time zones, reporting periods)
- **Aggregates** data at multiple geographic levels (block, neighborhood, district, city, county)
- **Validates** data quality and completeness automatically
- **Indexes** data for fast querying and analysis

This universal architecture enables rapid integration of new data sources from any municipality, transforming raw urban data into actionable intelligence for better city planning and civic engagement.